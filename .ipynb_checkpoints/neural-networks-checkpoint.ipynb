{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "From [brilliant.org](https://brilliant.org/practice/perceptron-limitations/?chapter=perceptrons):\n",
    "\n",
    "The **perceptron** algorithm **divides a vector space into two classes**. Colloquially speaking, for it to succeed on all points in training data, the **points must be completely separable**. This is known as **linear separability**, as we seek to find lines (or higher-dimensional equivalents) that correctly classify all of the data.\n",
    "\n",
    "The reason we use linear models is that they have many nice properties. For example, linear models are simple and have few parameters to learn, thus requiring less training data to learn reliably. Moreover, linear models are visually and intuitively appealing, providing intuition on understanding the structure of the decision boundaries. However, because theyâ€™re so simple, the perceptron algorithm has several limitations (see section Limitations of perceptron)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define `perceptron`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T03:58:52.883771Z",
     "start_time": "2019-03-08T03:58:52.856746Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron(w, x, y, i, iteration, max_i, cycle_error,\n",
    "              print_details=False):\n",
    "    \"\"\"\n",
    "    function emulating the logic of perceptron\n",
    "    \n",
    "    loss function is calculated as [[ y_i*(w dot x_i + b) <= 0 ]]\n",
    "    if misclassified (loss == True), adjust weights and bias\n",
    "    call the algorithm recursively until 'max_iterations' is reached\n",
    "    \n",
    "    param: w   -- np.array -- vector of weights (free term 'b' is included)\n",
    "    param: x   -- np.array -- array of vectors (arrays) of inputs\n",
    "                              (free term 'b' is included)\n",
    "    param: y   -- boolean  -- array of labelled results\n",
    "    param: i   -- int      -- current data point\n",
    "    param: iteration -- int -- current iteration of the algorithm\n",
    "    param: max_i     -- int -- max number of iterations allowed\n",
    "    param: cycle_error -- float -- sum of all errors in this cycle\n",
    "    \n",
    "    kwarg: print_details -- boolean -- print details of each iteration\n",
    "                                       (default=False)\n",
    "    \n",
    "    global variable: losses -- int -- number of losses \n",
    "                                      (updated by this function)\n",
    "    global variable: runs   -- int -- number of iterations\n",
    "                                      (updated by this function)\n",
    "    global variable: cycle -- int  -- current cycle\n",
    "                                      (updated by this function)\n",
    "    global variable: error_dict -- dict -- dictionary with total error\n",
    "                                           from each cycle\n",
    "    \n",
    "    returns: perceptron(w, x, y, i) -- recursively calls itself\n",
    "                                                  until 'max_i'\n",
    "                                                  is reached\n",
    "    \"\"\"\n",
    "    # global variables -- number of losses, number of runs\n",
    "    global losses, runs, cycle, error_dict\n",
    "    \n",
    "    # print headers\n",
    "    if iteration == 0: print(\"\\n----- Perceptron -----\")\n",
    "      \n",
    "    # classification -- w dot x_i (term 'b' included as last in 'w' and 'x')\n",
    "    classi = w.dot(x[i])\n",
    "    \n",
    "    # calculate the loss function\n",
    "    loss = y[i] * classi <= 0\n",
    "    \n",
    "    if print_details:\n",
    "        print(\"\\n---Iteration #\", iteration, \":\")\n",
    "        print(\"loss({0}) = y_i({1}) * w({2}) dot x_i({3})\"\n",
    "              .format(loss, y[i], w, x[i]))\n",
    "        print(\"w dot x_i = \", classi)\n",
    "    \n",
    "    # if misclassified, adjust weights\n",
    "    if loss:\n",
    "        # add error to 'cycle_error'\n",
    "        cycle_error += abs(classi)\n",
    "        # THIS PART MIGHT CAUSE ERRORS DUE TO +=\n",
    "        w += y[i] * x[i] # adjust vector of weights\n",
    "        losses += 1\n",
    "        \n",
    "        if print_details:\n",
    "            print(\"Error =\", abs(classi))\n",
    "            print(\"Adjusted wights:\", w)\n",
    "    \n",
    "    # count iterations\n",
    "    iteration += 1\n",
    "    runs = iteration\n",
    "    # move to next data point\n",
    "    i += 1\n",
    "    # reset 'i', if reached the end of 'x'\n",
    "    if i == len(x):\n",
    "        print(\"\\n--Cycle #{0} completed. From {1:,} records, {2:,}({3:.2f}%) \\\n",
    "were misclassified.\\n\".format(cycle, i, losses, losses / i * 100))\n",
    "        print(\"Total cycle error =\", cycle_error)\n",
    "        if losses == 0:\n",
    "            print(\"No records misclasified on this cycle. Exiting...\")\n",
    "            return\n",
    "        losses = 0      # reset losses for the next cycle\n",
    "        error_dict[cycle] = cycle_error # add cycle error to global 'error_dict'\n",
    "        cycle_error = 0 # reset error for the next cycle\n",
    "        i = 0           # reset 'i' for the next cycle\n",
    "        cycle += 1      # count cycles\n",
    "        \n",
    "    # continue until 'max_iterations' is reached\n",
    "    if i < max_i:\n",
    "        return perceptron(w, x, y, i, iteration, max_i, cycle_error, \n",
    "                          print_details=print_details)\n",
    "    else:\n",
    "        print(\"Max iterations reached, stopping...\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define `plot_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T04:06:38.880808Z",
     "start_time": "2019-03-08T04:06:38.865846Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_error():\n",
    "    \"\"\"\n",
    "    function to plot error from each cycle\n",
    "    \"\"\"\n",
    "    global error_dict\n",
    "    error_se = Series(error_dict)\n",
    "    \n",
    "    f, ax = plt.subplots(1, figsize=(6, 6))\n",
    "    ax.set_title(\"Total error by cycle\")\n",
    "    ax.set_xlabel(\"Cycle number\")\n",
    "    ax.set_ylabel(\"Sum of abs of all errors\")\n",
    "    ax.set_xticks(np.arange(len(error_se) + 1))\n",
    "    plt.plot(error_se, color='red')\n",
    "    ax.fill_between(x=error_se.index, y1=error_se, y2=0, \n",
    "                    color='red', alpha=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T03:58:53.921265Z",
     "start_time": "2019-03-08T03:58:53.887236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights -- vector w(0): [0. 0. 0.]\n",
      "\n",
      "Data points -- vectors x_i:\n",
      " [[-1.  1.  1.]\n",
      " [ 0. -1.  1.]\n",
      " [10.  1.  1.]]\n",
      "\n",
      "Results -- set of y: [ 1. -1.  1.]\n",
      "\n",
      "----- Perceptron -----\n",
      "\n",
      "---Iteration # 0 :\n",
      "loss(True) = y_i(1.0) * w([0. 0. 0.]) dot x_i([-1.  1.  1.])\n",
      "w dot x_i =  0.0\n",
      "Error = 0.0\n",
      "Adjusted wights: [-1.  1.  1.]\n",
      "\n",
      "---Iteration # 1 :\n",
      "loss(True) = y_i(-1.0) * w([-1.  1.  1.]) dot x_i([ 0. -1.  1.])\n",
      "w dot x_i =  0.0\n",
      "Error = 0.0\n",
      "Adjusted wights: [-1.  2.  0.]\n",
      "\n",
      "---Iteration # 2 :\n",
      "loss(True) = y_i(1.0) * w([-1.  2.  0.]) dot x_i([10.  1.  1.])\n",
      "w dot x_i =  -8.0\n",
      "Error = 8.0\n",
      "Adjusted wights: [9. 3. 1.]\n",
      "\n",
      "--Cycle #1 completed. From 3 records, 3(100.00%) were misclassified.\n",
      "\n",
      "Total cycle error = 8.0\n",
      "\n",
      "---Iteration # 3 :\n",
      "loss(True) = y_i(1.0) * w([9. 3. 1.]) dot x_i([-1.  1.  1.])\n",
      "w dot x_i =  -5.0\n",
      "Error = 5.0\n",
      "Adjusted wights: [8. 4. 2.]\n",
      "\n",
      "---Iteration # 4 :\n",
      "loss(False) = y_i(-1.0) * w([8. 4. 2.]) dot x_i([ 0. -1.  1.])\n",
      "w dot x_i =  -2.0\n",
      "\n",
      "---Iteration # 5 :\n",
      "loss(False) = y_i(1.0) * w([8. 4. 2.]) dot x_i([10.  1.  1.])\n",
      "w dot x_i =  86.0\n",
      "\n",
      "--Cycle #2 completed. From 3 records, 1(33.33%) were misclassified.\n",
      "\n",
      "Total cycle error = 5.0\n",
      "\n",
      "---Iteration # 6 :\n",
      "loss(True) = y_i(1.0) * w([8. 4. 2.]) dot x_i([-1.  1.  1.])\n",
      "w dot x_i =  -2.0\n",
      "Error = 2.0\n",
      "Adjusted wights: [7. 5. 3.]\n",
      "\n",
      "---Iteration # 7 :\n",
      "loss(False) = y_i(-1.0) * w([7. 5. 3.]) dot x_i([ 0. -1.  1.])\n",
      "w dot x_i =  -2.0\n",
      "\n",
      "---Iteration # 8 :\n",
      "loss(False) = y_i(1.0) * w([7. 5. 3.]) dot x_i([10.  1.  1.])\n",
      "w dot x_i =  78.0\n",
      "\n",
      "--Cycle #3 completed. From 3 records, 1(33.33%) were misclassified.\n",
      "\n",
      "Total cycle error = 2.0\n",
      "\n",
      "---Iteration # 9 :\n",
      "loss(False) = y_i(1.0) * w([7. 5. 3.]) dot x_i([-1.  1.  1.])\n",
      "w dot x_i =  1.0\n",
      "\n",
      "---Iteration # 10 :\n",
      "loss(False) = y_i(-1.0) * w([7. 5. 3.]) dot x_i([ 0. -1.  1.])\n",
      "w dot x_i =  -2.0\n",
      "\n",
      "---Iteration # 11 :\n",
      "loss(False) = y_i(1.0) * w([7. 5. 3.]) dot x_i([10.  1.  1.])\n",
      "w dot x_i =  78.0\n",
      "\n",
      "--Cycle #4 completed. From 3 records, 0(0.00%) were misclassified.\n",
      "\n",
      "Total cycle error = 0\n",
      "No records misclasified on this cycle. Exiting...\n"
     ]
    }
   ],
   "source": [
    "i = 0                # variable to track current data point\n",
    "cycle = 1        # variable to track number of the cycle\n",
    "iteration = 0        # starting value for iteration tracking\n",
    "max_i = 100           # max iterations allowed \n",
    "losses = 0           # var to track number of losses per cycle, updated by func\n",
    "cycle_error = 0      # var to track total cycle error\n",
    "runs = 0             # var to track total number of runs, updated by function\n",
    "error_dict = dict()  # dictionary to store total error from each cycle\n",
    "\n",
    "# starting vector of weights \n",
    "# (last coordinate represents 'b' from 'w * x_i + b')\n",
    "w = np.array([0., 0., 0.])\n",
    "\n",
    "# set of vectors of points (last coordinate represents 'b' from 'w * x_i + b')\n",
    "x = np.array(\n",
    "    [np.array([-1., 1., 1.]),\n",
    "     np.array([0., -1., 1.]),\n",
    "     np.array([10, 1., 1.])]\n",
    "    )\n",
    "\n",
    "# set of results\n",
    "y = np.array([1., -1., 1.])\n",
    "\n",
    "print(\"Starting weights -- vector w(0):\", w)\n",
    "print(\"\\nData points -- vectors x_i:\\n\", x)\n",
    "print(\"\\nResults -- set of y:\", y)\n",
    "\n",
    "perceptron(w, x, y, i, iteration, max_i, cycle_error, print_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T03:58:58.220379Z",
     "start_time": "2019-03-08T03:58:58.215426Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T04:06:39.494182Z",
     "start_time": "2019-03-08T04:06:39.194205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training sets with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T03:42:26.634719Z",
     "start_time": "2019-03-08T03:42:26.607689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights -- vector w(0): [0 0 0]\n",
      "\n",
      "Data points -- vectors x_i:\n",
      " [[-1  1  1]\n",
      " [ 0 -1  1]\n",
      " [10  1  1]]\n",
      "\n",
      "Results -- set of y: [ 1 -1  1]\n",
      "\n",
      "----- Perceptron -----\n",
      "\n",
      "---Iteration # 0 :\n",
      "loss(True) = y_i(1) * w([0 0 0]) dot x_i([-1  1  1])\n",
      "w dot x_i =  0\n",
      "Error = 0\n",
      "Adjusted wights: [-1  1  1]\n",
      "\n",
      "---Iteration # 1 :\n",
      "loss(True) = y_i(-1) * w([-1  1  1]) dot x_i([ 0 -1  1])\n",
      "w dot x_i =  0\n",
      "Error = 0\n",
      "Adjusted wights: [-1  2  0]\n",
      "\n",
      "---Iteration # 2 :\n",
      "loss(True) = y_i(1) * w([-1  2  0]) dot x_i([10  1  1])\n",
      "w dot x_i =  -8\n",
      "Error = 8\n",
      "Adjusted wights: [9 3 1]\n",
      "\n",
      "--Cycle #1 completed. From 3 records, 3(100.00%) were misclassified.\n",
      "\n",
      "Total cycle error = 8\n",
      "\n",
      "---Iteration # 3 :\n",
      "loss(True) = y_i(1) * w([9 3 1]) dot x_i([-1  1  1])\n",
      "w dot x_i =  -5\n",
      "Error = 5\n",
      "Adjusted wights: [8 4 2]\n",
      "\n",
      "---Iteration # 4 :\n",
      "loss(False) = y_i(-1) * w([8 4 2]) dot x_i([ 0 -1  1])\n",
      "w dot x_i =  -2\n",
      "\n",
      "---Iteration # 5 :\n",
      "loss(False) = y_i(1) * w([8 4 2]) dot x_i([10  1  1])\n",
      "w dot x_i =  86\n",
      "\n",
      "--Cycle #2 completed. From 3 records, 1(33.33%) were misclassified.\n",
      "\n",
      "Total cycle error = 5\n",
      "\n",
      "---Iteration # 6 :\n",
      "loss(True) = y_i(1) * w([8 4 2]) dot x_i([-1  1  1])\n",
      "w dot x_i =  -2\n",
      "Error = 2\n",
      "Adjusted wights: [7 5 3]\n",
      "\n",
      "---Iteration # 7 :\n",
      "loss(False) = y_i(-1) * w([7 5 3]) dot x_i([ 0 -1  1])\n",
      "w dot x_i =  -2\n",
      "\n",
      "---Iteration # 8 :\n",
      "loss(False) = y_i(1) * w([7 5 3]) dot x_i([10  1  1])\n",
      "w dot x_i =  78\n",
      "\n",
      "--Cycle #3 completed. From 3 records, 1(33.33%) were misclassified.\n",
      "\n",
      "Total cycle error = 2\n",
      "\n",
      "---Iteration # 9 :\n",
      "loss(False) = y_i(1) * w([7 5 3]) dot x_i([-1  1  1])\n",
      "w dot x_i =  1\n",
      "\n",
      "---Iteration # 10 :\n",
      "loss(False) = y_i(-1) * w([7 5 3]) dot x_i([ 0 -1  1])\n",
      "w dot x_i =  -2\n",
      "\n",
      "---Iteration # 11 :\n",
      "loss(False) = y_i(1) * w([7 5 3]) dot x_i([10  1  1])\n",
      "w dot x_i =  78\n",
      "\n",
      "--Cycle #4 completed. From 3 records, 0(0.00%) were misclassified.\n",
      "\n",
      "Total cycle error = 0\n",
      "No records misclasified on this cycle. Exiting...\n"
     ]
    }
   ],
   "source": [
    "i = 0                # variable to track current data point\n",
    "cycle = 1        # variable to track number of the cycle\n",
    "iteration = 0        # starting value for iteration tracking\n",
    "max_i = 100           # max iterations allowed \n",
    "losses = 0           # var to track number of losses per cycle, updated by func\n",
    "cycle_error = 0      # var to track total cycle error\n",
    "runs = 0             # var to track total number of runs, updated by function\n",
    "\n",
    "# starting vector of weights \n",
    "# (last coordinate represents 'b' from 'w * x_i + b')\n",
    "w = np.array([0, 0, 0])\n",
    "\n",
    "# set of vectors of points (last coordinate represents 'b' from 'w * x_i + b')\n",
    "x = np.array(\n",
    "    [np.array([-1, 1, 1]),\n",
    "     np.array([0, -1, 1]),\n",
    "     np.array([10, 1, 1])]\n",
    "    )\n",
    "\n",
    "# set of results\n",
    "y = np.array([1, -1, 1])\n",
    "\n",
    "print(\"Starting weights -- vector w(0):\", w)\n",
    "print(\"\\nData points -- vectors x_i:\\n\", x)\n",
    "print(\"\\nResults -- set of y:\", y)\n",
    "\n",
    "perceptron(w, x, y, i, iteration, max_i, cycle_error, print_details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, an outlier causes the perceptron weight values to â€˜overcorrectâ€™ for misclassifying the outlier, and so it could takes more iterations to account for this.\n",
    "\n",
    "This is also evident from an earlier computation. In the case with no bias term (a hyperplane through the origin), each step changed the signed distance from a misclassified point to the boundary by $|x|^2$. Thus, outliers far from the hyperplane will cause very large changes, and the algorithm will accordingly take longer to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Influence of initialization values\n",
    "\n",
    "Given two different initialization values (for weights and bias), but the same training data, is this learning algorithm guaranteed to converge to the same weight and bias parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Starting at $w(0) = \\binom{5}{5}$ and $b(5) = 0$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T03:42:28.258209Z",
     "start_time": "2019-03-08T03:42:28.240141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights -- vector w(0): [5 5 5]\n",
      "\n",
      "Data points -- vectors x_i:\n",
      " [[-1  1  1]\n",
      " [ 0 -1  1]\n",
      " [10  1  1]]\n",
      "\n",
      "Results -- set of y: [ 1 -1  1]\n",
      "\n",
      "----- Perceptron -----\n",
      "\n",
      "--Cycle #1 completed. From 3 records, 1(33.33%) were misclassified.\n",
      "\n",
      "Total cycle error = 0\n",
      "\n",
      "--Cycle #2 completed. From 3 records, 0(0.00%) were misclassified.\n",
      "\n",
      "Total cycle error = 0\n",
      "No records misclasified on this cycle. Exiting...\n"
     ]
    }
   ],
   "source": [
    "i = 0                # variable to track current data point\n",
    "cycle = 1        # variable to track number of the cycle\n",
    "iteration = 0        # starting value for iteration tracking\n",
    "max_i = 100           # max iterations allowed \n",
    "losses = 0           # var to track number of losses per cycle, updated by func\n",
    "cycle_error = 0      # var to track total cycle error\n",
    "runs = 0             # var to track total number of runs, updated by function\n",
    "\n",
    "# starting vector of weights \n",
    "# (last coordinate represents 'b' from 'w * x_i + b')\n",
    "w = np.array([5, 5, 5])\n",
    "\n",
    "# set of vectors of points (last coordinate represents 'b' from 'w * x_i + b')\n",
    "x = np.array(\n",
    "    [np.array([-1, 1, 1]),\n",
    "     np.array([0, -1, 1]),\n",
    "     np.array([10, 1, 1])]\n",
    "    )\n",
    "\n",
    "# set of results\n",
    "y = np.array([1, -1, 1])\n",
    "\n",
    "print(\"Starting weights -- vector w(0):\", w)\n",
    "print(\"\\nData points -- vectors x_i:\\n\", x)\n",
    "print(\"\\nResults -- set of y:\", y)\n",
    "\n",
    "perceptron(w, x, y, i, iteration, max_i, cycle_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converged to a different point**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Starting at $w(0) = \\binom{-13}{-7}$ and $b(0) = 1$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T03:43:15.481267Z",
     "start_time": "2019-03-08T03:43:15.457253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights -- vector w(0): [-13  -7   1]\n",
      "\n",
      "Data points -- vectors x_i:\n",
      " [[-1  1  1]\n",
      " [ 0 -1  1]\n",
      " [10  1  1]]\n",
      "\n",
      "Results -- set of y: [ 1 -1  1]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "perceptron() missing 1 required positional argument: 'cycle_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-74ad283e37d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nResults -- set of y:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mperceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: perceptron() missing 1 required positional argument: 'cycle_error'"
     ]
    }
   ],
   "source": [
    "i = 0                # variable to track current data point\n",
    "cycle = 1        # variable to track number of the cycle\n",
    "iteration = 0        # starting value for iteration tracking\n",
    "max_i = 100           # max iterations allowed \n",
    "losses = 0           # var to track number of losses per cycle, updated by func\n",
    "runs = 0             # var to track total number of runs, updated by function\n",
    "\n",
    "# starting vector of weights \n",
    "# (last coordinate represents 'b' from 'w * x_i + b')\n",
    "w = np.array([-13, -7, 1])\n",
    "\n",
    "# set of vectors of points (last coordinate represents 'b' from 'w * x_i + b')\n",
    "x = np.array(\n",
    "    [np.array([-1, 1, 1]),\n",
    "     np.array([0, -1, 1]),\n",
    "     np.array([10, 1, 1])]\n",
    "    )\n",
    "\n",
    "# set of results\n",
    "y = np.array([1, -1, 1])\n",
    "\n",
    "print(\"Starting weights -- vector w(0):\", w)\n",
    "print(\"\\nData points -- vectors x_i:\\n\", x)\n",
    "print(\"\\nResults -- set of y:\", y)\n",
    "\n",
    "perceptron(w, x, y, i, iteration, max_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converged to a different point**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This highlights an **important limitation of perceptron** - while we can find a hyperplane that linearly separates the data, we donâ€™t know this hyperplane is even the best one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limitations of perceptron\n",
    "\n",
    "A massive drawback of the naive perceptron learning algorithm is that it **will not converge if the training data are not linearly separable**. Our naive perceptron algorithm can't classify data that is not linearly separable, but we can get around this.\n",
    "\n",
    "Previously, we iterated $w$ and $b$ until there were no more errors. Since we know we'll never get no errors, every time we update $w$ calculate its error rate on all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T03:29:57.502546Z",
     "start_time": "2019-03-08T03:29:57.476570Z"
    }
   },
   "outputs": [],
   "source": [
    "def perceptron(w, x, y, i, iteration, max_i, cycle_error):\n",
    "    \"\"\"\n",
    "    function emulating the logic of perceptron\n",
    "    \n",
    "    loss function is calculated as [[ y_i*(w dot x_i + b) <= 0 ]]\n",
    "    if misclassified (loss == True), adjust weights and bias\n",
    "    call the algorithm recursively until 'max_iterations' is reached\n",
    "    \n",
    "    param: w   -- np.array -- vector of weights (free term 'b' is included)\n",
    "    param: x   -- np.array -- array of vectors (arrays) of inputs\n",
    "                              (free term 'b' is included)\n",
    "    param: y   -- boolean  -- array of labelled results\n",
    "    param: i   -- int      -- current data point\n",
    "    param: iteration -- int -- current iteration of the algorithm\n",
    "    param: max_i     -- int -- max number of iterations allowed\n",
    "    param: cycle_error -- float -- sum of all errors in this cycle\n",
    "    \n",
    "    global variable: losses -- int -- number of losses \n",
    "                                      (updated by this function)\n",
    "    global variable: runs   -- int -- number of iterations\n",
    "                                      (updated by this function)\n",
    "    global variable: cycle -- int  -- current cycle\n",
    "                                      (updated by this function)                                  \n",
    "    \n",
    "    returns: perceptron(w, x, y, i) -- recursively calls itself\n",
    "                                                  until 'max_iterations'\n",
    "                                                  is reached\n",
    "    \"\"\"\n",
    "    # global variables -- number of losses, number of runs\n",
    "    global losses, runs, cycle\n",
    "    \n",
    "    # print headers\n",
    "    if iteration == 0: print(\"\\n----- Perceptron -----\")\n",
    "    if i == 0: print(\"\\n--- starting cycle #{0} through data point...\"\n",
    "                     .format(cycle))\n",
    "    \n",
    "    # classification -- w dot x_i (term 'b' included as last in 'w' and 'x')\n",
    "    classi = w.dot(x[i])\n",
    "    \n",
    "    # calculate the loss function\n",
    "    loss = y[i] * classi <= 0\n",
    "    \n",
    "    print(\"\\n---Iteration #\", iteration, \":\")\n",
    "    print(\"loss({0}) = y_i({1}) * w({2}) dot x_i({3})\"\n",
    "          .format(loss, y[i], w, x[i]))\n",
    "    print(\"w dot x_i = \", classi)\n",
    "    \n",
    "    # if misclassified, adjust weights\n",
    "    if loss:\n",
    "        print(\"Error =\", abs(classi))\n",
    "        # add error to 'cycle_error'\n",
    "        cycle_error += abs(classi)\n",
    "        print(\"Starting weights:\", w)\n",
    "        # THIS PART MIGHT CAUSE ERRORS DUE TO +=\n",
    "        w += y[i] * x[i] # adjust vector of weights\n",
    "        losses += 1\n",
    "        print(\"Adjusted wights:\", w)\n",
    "    \n",
    "    # count iterations\n",
    "    iteration += 1\n",
    "    runs = iteration\n",
    "    # move to next data point\n",
    "    i += 1\n",
    "    # reset 'i', if reached the end of 'x'\n",
    "    if i == len(x):\n",
    "        print(\"\\n--Cycle #{0} completed. From {1:,} records, {2:,}({3:.2f}%) \\\n",
    "were misclassified.\\n\".format(cycle, i, losses, losses / i * 100))\n",
    "        print(\"Total cycle error =\", cycle_error)\n",
    "        if losses == 0:\n",
    "            print(\"No records misclasified on this cycle. Exiting...\")\n",
    "            return\n",
    "        losses = 0      # reset losses for the next cycle\n",
    "        cycle_error = 0 # reset error for the next cycle\n",
    "        i = 0           # reset 'i' for the next cycle\n",
    "        cycle += 1      # count cycles\n",
    "        \n",
    "    # continue until 'max_iterations' is reached\n",
    "    if i < max_i:\n",
    "        return perceptron(w, x, y, i, iteration, max_i, cycle_error)\n",
    "    else:\n",
    "        print(\"Max iterations reached, stopping...\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T03:29:57.992984Z",
     "start_time": "2019-03-08T03:29:57.984034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = [1, 1, 2, 3, 4, 5]\n",
    "sum(li[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T03:29:58.820652Z",
     "start_time": "2019-03-08T03:29:58.783617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights -- vector w(0): [-13  -7   1]\n",
      "\n",
      "Data points -- vectors x_i:\n",
      " [[-1  1  1]\n",
      " [ 0 -1  1]\n",
      " [10  1  1]]\n",
      "\n",
      "Results -- set of y: [ 1 -1  1]\n",
      "\n",
      "----- Perceptron -----\n",
      "\n",
      "--- starting cycle #1 through data point...\n",
      "\n",
      "---Iteration # 0 :\n",
      "loss(False) = y_i(1) * w([-13  -7   1]) dot x_i([-1  1  1])\n",
      "w dot x_i =  7\n",
      "\n",
      "---Iteration # 1 :\n",
      "loss(True) = y_i(-1) * w([-13  -7   1]) dot x_i([ 0 -1  1])\n",
      "w dot x_i =  8\n",
      "Error = 8\n",
      "Starting weights: [-13  -7   1]\n",
      "Adjusted wights: [-13  -6   0]\n",
      "\n",
      "---Iteration # 2 :\n",
      "loss(True) = y_i(1) * w([-13  -6   0]) dot x_i([10  1  1])\n",
      "w dot x_i =  -136\n",
      "Error = 136\n",
      "Starting weights: [-13  -6   0]\n",
      "Adjusted wights: [-3 -5  1]\n",
      "\n",
      "--Cycle #1 completed. From 3 records, 2(66.67%) were misclassified.\n",
      "\n",
      "Total cycle error = 144\n",
      "\n",
      "--- starting cycle #2 through data point...\n",
      "\n",
      "---Iteration # 3 :\n",
      "loss(True) = y_i(1) * w([-3 -5  1]) dot x_i([-1  1  1])\n",
      "w dot x_i =  -1\n",
      "Error = 1\n",
      "Starting weights: [-3 -5  1]\n",
      "Adjusted wights: [-4 -4  2]\n",
      "\n",
      "---Iteration # 4 :\n",
      "loss(True) = y_i(-1) * w([-4 -4  2]) dot x_i([ 0 -1  1])\n",
      "w dot x_i =  6\n",
      "Error = 6\n",
      "Starting weights: [-4 -4  2]\n",
      "Adjusted wights: [-4 -3  1]\n",
      "\n",
      "---Iteration # 5 :\n",
      "loss(True) = y_i(1) * w([-4 -3  1]) dot x_i([10  1  1])\n",
      "w dot x_i =  -42\n",
      "Error = 42\n",
      "Starting weights: [-4 -3  1]\n",
      "Adjusted wights: [ 6 -2  2]\n",
      "\n",
      "--Cycle #2 completed. From 3 records, 3(100.00%) were misclassified.\n",
      "\n",
      "Total cycle error = 49\n",
      "\n",
      "--- starting cycle #3 through data point...\n",
      "\n",
      "---Iteration # 6 :\n",
      "loss(True) = y_i(1) * w([ 6 -2  2]) dot x_i([-1  1  1])\n",
      "w dot x_i =  -6\n",
      "Error = 6\n",
      "Starting weights: [ 6 -2  2]\n",
      "Adjusted wights: [ 5 -1  3]\n",
      "\n",
      "---Iteration # 7 :\n",
      "loss(True) = y_i(-1) * w([ 5 -1  3]) dot x_i([ 0 -1  1])\n",
      "w dot x_i =  4\n",
      "Error = 4\n",
      "Starting weights: [ 5 -1  3]\n",
      "Adjusted wights: [5 0 2]\n",
      "\n",
      "---Iteration # 8 :\n",
      "loss(False) = y_i(1) * w([5 0 2]) dot x_i([10  1  1])\n",
      "w dot x_i =  52\n",
      "\n",
      "--Cycle #3 completed. From 3 records, 2(66.67%) were misclassified.\n",
      "\n",
      "Total cycle error = 10\n",
      "\n",
      "--- starting cycle #4 through data point...\n",
      "\n",
      "---Iteration # 9 :\n",
      "loss(True) = y_i(1) * w([5 0 2]) dot x_i([-1  1  1])\n",
      "w dot x_i =  -3\n",
      "Error = 3\n",
      "Starting weights: [5 0 2]\n",
      "Adjusted wights: [4 1 3]\n",
      "\n",
      "---Iteration # 10 :\n",
      "loss(True) = y_i(-1) * w([4 1 3]) dot x_i([ 0 -1  1])\n",
      "w dot x_i =  2\n",
      "Error = 2\n",
      "Starting weights: [4 1 3]\n",
      "Adjusted wights: [4 2 2]\n",
      "\n",
      "---Iteration # 11 :\n",
      "loss(False) = y_i(1) * w([4 2 2]) dot x_i([10  1  1])\n",
      "w dot x_i =  44\n",
      "\n",
      "--Cycle #4 completed. From 3 records, 2(66.67%) were misclassified.\n",
      "\n",
      "Total cycle error = 5\n",
      "\n",
      "--- starting cycle #5 through data point...\n",
      "\n",
      "---Iteration # 12 :\n",
      "loss(True) = y_i(1) * w([4 2 2]) dot x_i([-1  1  1])\n",
      "w dot x_i =  0\n",
      "Error = 0\n",
      "Starting weights: [4 2 2]\n",
      "Adjusted wights: [3 3 3]\n",
      "\n",
      "---Iteration # 13 :\n",
      "loss(True) = y_i(-1) * w([3 3 3]) dot x_i([ 0 -1  1])\n",
      "w dot x_i =  0\n",
      "Error = 0\n",
      "Starting weights: [3 3 3]\n",
      "Adjusted wights: [3 4 2]\n",
      "\n",
      "---Iteration # 14 :\n",
      "loss(False) = y_i(1) * w([3 4 2]) dot x_i([10  1  1])\n",
      "w dot x_i =  36\n",
      "\n",
      "--Cycle #5 completed. From 3 records, 2(66.67%) were misclassified.\n",
      "\n",
      "Total cycle error = 0\n",
      "\n",
      "--- starting cycle #6 through data point...\n",
      "\n",
      "---Iteration # 15 :\n",
      "loss(False) = y_i(1) * w([3 4 2]) dot x_i([-1  1  1])\n",
      "w dot x_i =  3\n",
      "\n",
      "---Iteration # 16 :\n",
      "loss(False) = y_i(-1) * w([3 4 2]) dot x_i([ 0 -1  1])\n",
      "w dot x_i =  -2\n",
      "\n",
      "---Iteration # 17 :\n",
      "loss(False) = y_i(1) * w([3 4 2]) dot x_i([10  1  1])\n",
      "w dot x_i =  36\n",
      "\n",
      "--Cycle #6 completed. From 3 records, 0(0.00%) were misclassified.\n",
      "\n",
      "Total cycle error = 0\n",
      "No records misclasified on this cycle. Exiting...\n"
     ]
    }
   ],
   "source": [
    "i = 0                # var to track current data point\n",
    "cycle = 1            # var to track number of the cycle\n",
    "iteration = 0        # starting value for iteration tracking\n",
    "max_i = 100          # max iterations allowed \n",
    "losses = 0           # var to track number of losses per cycle, updated by func\n",
    "cycle_error = 0      # var to track total cycle error\n",
    "runs = 0             # var to track total number of runs, updated by function\n",
    "\n",
    "# starting vector of weights \n",
    "# (last coordinate represents 'b' from 'w * x_i + b')\n",
    "w = np.array([-13, -7, 1])\n",
    "\n",
    "# set of vectors of points (last coordinate represents 'b' from 'w * x_i + b')\n",
    "x = np.array(\n",
    "    [np.array([-1, 1, 1]),\n",
    "     np.array([0, -1, 1]),\n",
    "     np.array([10, 1, 1])]\n",
    "    )\n",
    "\n",
    "# set of results\n",
    "y = np.array([1, -1, 1])\n",
    "\n",
    "print(\"Starting weights -- vector w(0):\", w)\n",
    "print(\"\\nData points -- vectors x_i:\\n\", x)\n",
    "print(\"\\nResults -- set of y:\", y)\n",
    "\n",
    "perceptron(w, x, y, i, iteration, max_i, cycle_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
